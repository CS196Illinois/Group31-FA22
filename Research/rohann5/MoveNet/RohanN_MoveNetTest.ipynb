{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa73fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Link is Important: https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/3 \n",
    "#Link to Tutorial I followed: https://www.youtube.com/watch?v=SSW9LzOJSus&ab_channel=NicholasRenotte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f78218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.10.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (4.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.50.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (65.5.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (22.9.24)\n",
      "Requirement already satisfied: packaging in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.23.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (2.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (3.19.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (0.27.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (14.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.37.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.6.15.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rohan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.10.0 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce4abd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b128e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_lightning_3.tflite')\n",
    "#interpreter = tf.lite.Interpreter(model_path='lite-model_movenet_singlepose_thunder_3.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01e1053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 192, 192,   3]),\n",
       "  'shape_signature': array([  1, 192, 192,   3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ignore, just for testing\n",
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d721cfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(192 in interpreter.get_input_details()[0]['shape']) #For testing only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ea4e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 312,\n",
       "  'shape': array([ 1,  1, 17,  3]),\n",
       "  'shape_signature': array([ 1,  1, 17,  3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ignore, just for testing\n",
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c5ba832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing Keypoints\n",
    "\n",
    "def draw_keypoints(frame, keypoints, confidence):\n",
    "    \"\"\"\n",
    "    Draws in the locations of the key joints\n",
    "    \"\"\"\n",
    "    y, x, c = frame.shape #y coordinate, x, coordginate, the channel coordinate\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1])) #the third coordinate in our keypoints is the confidence value, so we multiply by one to maintain that coordinate\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp #extracting our y, our x, \n",
    "        if kp_conf > confidence:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0, 255, 0), -1) #last three parameters are size, color, fill\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc17254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary that represents the connections for the function below\n",
    "# the value is the letter that corresponds to the color of the edge (they are just here, we are not really using them)\n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d48f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing Edges\n",
    "\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape #y coordinate, x, coordginate, the channel coordinate\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1])) #the third coordinate in our keypoints is the confidence value, so we multiply by one to maintain that coordinate\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):\n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1395a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting to calculate angles\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"\n",
    "    Given three keypoints, calculate the angle between them\n",
    "    \"\"\"\n",
    "    #In the mediapipe implementation, the points needed to be converted into numpy.ndarray type\n",
    "    #Here, the points from the keypoints are already in this type, so we don't need to convert\n",
    "        #p[0] ->  y-coordinate\n",
    "        #p[1] -> x-coordinate\n",
    "    \n",
    "    radians = np.arctan2(c[0] - b[0], c[1] - b[1]) - np.arctan2(a[0] - b[0], a[1] - b[1])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    \n",
    "    return angle\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2076877b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter:  1\n",
      "counter:  2\n",
      "counter:  3\n",
      "counter:  4\n",
      "counter:  5\n",
      "counter:  6\n",
      "counter:  7\n",
      "counter:  8\n",
      "counter:  9\n",
      "counter:  10\n",
      "counter:  11\n"
     ]
    }
   ],
   "source": [
    "#Making Detections\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "counter = 0\n",
    "stage = None\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    #Need to reshape image. Movenet Architecture expects an image of dimensions 192x192x3\n",
    "    img = frame.copy() #makes a copy of the captured frame and saves it to a variable 'img'\n",
    "    #to resize, we need to encapsulate it inside another array (that's what expand_dims does)\n",
    "    #the resizing happens with the resize_with_pad function, where we give it the proper dimensions. \n",
    "    img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192, 192) #For Lightning\n",
    "    #img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 256, 256) #For Thunder\n",
    "\n",
    "    #Image needs to be represented as a float32 tensor, that is what the below line does\n",
    "    input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    #Set input and Output (using the TF interpreter)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    #Make Predictions\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.array(input_image)) #Setting input details equal to input image\n",
    "    interpreter.invoke() #invoking (making) our prediction\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index']) # getting output details\n",
    "    #print(keypoints_with_scores)\n",
    "    \n",
    "    try:\n",
    "        left_shoulder = keypoints_with_scores[0][0][5]\n",
    "        left_elbow = keypoints_with_scores[0][0][7]\n",
    "        left_wrist = keypoints_with_scores[0][0][9]\n",
    "        \n",
    "        angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "        #print(angle)\n",
    "        \n",
    "#         #Visualize (purely just to put this on the feed)\n",
    "#         cv2.putText(image, str(angle), \n",
    "#                     tuple(np.multiply(left_elbow, [640, 480]).astype(int)), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "#                    )\n",
    "        \n",
    "        #Curl Counter Logic (this might need to be better lol)\n",
    "        if angle > 160:\n",
    "            stage = \"down\"\n",
    "        if angle < 30 and stage == \"down\":\n",
    "            stage = \"up\"\n",
    "            counter += 1\n",
    "            print(\"counter: \", counter)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #Rendering\n",
    "    draw_connections(frame, keypoints_with_scores, EDGES, 0.5)\n",
    "    draw_keypoints(frame, keypoints_with_scores, 0.5)\n",
    "    \n",
    "    #this tiny snippet is just for naming the camera properly based on the model we r using lol\n",
    "    if 192 in interpreter.get_input_details()[0]['shape']:\n",
    "        cv2.imshow('MoveNet Lightning', frame)\n",
    "    if 256 in interpreter.get_input_details()[0]['shape']:\n",
    "        cv2.imshow('MoveNet Thunder', frame)\n",
    "    #Exiting the Camera (Press q)\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bdb8b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 17, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_with_scores.shape #For testing (this is as expected from the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc933525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs\n",
    "# A float32 tensor of shape [1, 1, 17, 3].\n",
    "        # The first two channels of the last dimension represents the yx coordinates (normalized to image frame, i.e. range in [0.0, 1.0]) of the 17 keypoints \n",
    "        #(in the order of: [nose, left eye, right eye, left ear, right ear, left shoulder, right shoulder, left elbow, right elbow, left wrist, right wrist, left hip, right hip, left knee, right knee, left ankle, right ankle]).\n",
    "        # The third channel of the last dimension represents the prediction confidence scores of each keypoint, also in the range [0.0, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b2cbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64665157, 0.6305033 , 0.7997859 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the order of body parts given in the above cell\n",
    "right_eye = keypoints_with_scores[0][0][2]\n",
    "left_elbow = keypoints_with_scores[0][0][7]\n",
    "left_elbow #printing one of them out to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46557de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([310, 403])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(left_elbow[:2]*[480,640]).astype(int) #standardized coordinates to frame coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a58fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
